{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/GenreClassData_30s.txt', sep='\\t')\n",
    "data[\"TrackID\"] = range(len(data))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = data[data['Type'] == 'Train']\n",
    "test = data[data['Type'] == 'Test']\n",
    "\n",
    "\n",
    "#all_features = [col for col in data.columns if col not in ['Track ID','TrackID', 'File', 'GenreID', 'Genre', 'Type']]\n",
    "'''all_features = [\n",
    "    'zero_cross_rate_mean','zero_cross_rate_std','rmse_mean','rmse_var',\n",
    "    'spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var',\n",
    "    'spectral_rolloff_mean','spectral_rolloff_var','spectral_contrast_mean','spectral_contrast_var',\n",
    "    'spectral_flatness_mean','spectral_flatness_var',\n",
    "    'chroma_stft_1_mean','chroma_stft_2_mean','chroma_stft_3_mean','chroma_stft_4_mean',\n",
    "    'chroma_stft_5_mean','chroma_stft_6_mean','chroma_stft_7_mean','chroma_stft_8_mean',\n",
    "    'chroma_stft_9_mean','chroma_stft_10_mean','chroma_stft_11_mean','chroma_stft_12_mean',\n",
    "    'chroma_stft_1_std','chroma_stft_2_std','chroma_stft_3_std','chroma_stft_4_std',\n",
    "    'chroma_stft_5_std','chroma_stft_6_std','chroma_stft_7_std','chroma_stft_8_std',\n",
    "    'chroma_stft_9_std','chroma_stft_10_std','chroma_stft_11_std','chroma_stft_12_std',\n",
    "    'tempo',\n",
    "    'mfcc_1_mean','mfcc_2_mean','mfcc_3_mean','mfcc_4_mean','mfcc_5_mean','mfcc_6_mean',\n",
    "    'mfcc_7_mean','mfcc_8_mean','mfcc_9_mean','mfcc_10_mean','mfcc_11_mean','mfcc_12_mean',\n",
    "    'mfcc_1_std','mfcc_2_std','mfcc_3_std','mfcc_4_std','mfcc_5_std','mfcc_6_std',\n",
    "    'mfcc_7_std','mfcc_8_std','mfcc_9_std','mfcc_10_std','mfcc_11_std','mfcc_12_std'\n",
    "]'''\n",
    "all_features = [\n",
    "    'zero_cross_rate_mean','zero_cross_rate_std','rmse_mean','rmse_var',\n",
    "    'spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var',\n",
    "    'spectral_rolloff_mean','spectral_rolloff_var','spectral_contrast_mean','spectral_contrast_var',\n",
    "    'spectral_flatness_mean','spectral_flatness_var',\n",
    "    'chroma_stft_7_mean',\n",
    "    \n",
    "    'tempo',\n",
    "    'mfcc_1_mean','mfcc_2_mean','mfcc_3_mean','mfcc_4_mean','mfcc_5_mean','mfcc_6_mean',\n",
    "\n",
    "    'mfcc_2_std','mfcc_3_std','mfcc_4_std','mfcc_5_std', 'mfcc_7_std'\n",
    "]\n",
    "#Erfaringer: \n",
    "#'chroma_stft_x_std' er elendig, drar ned accuracy\n",
    "features = all_features\n",
    "\n",
    "#features = ['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean', 'chroma_stft_10_mean']\n",
    "\n",
    "targets = ['Genre']\n",
    "\n",
    "# feature data\n",
    "X_train, y_train = train[features], train[targets]\n",
    "X_test, y_test = test[features], test[targets]\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)      # compute μ,σ on TRAINING data only\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataclass for storing the structured data\n",
    "@dataclass(eq=False)\n",
    "class Cluster:\n",
    "    mean: np.ndarray\n",
    "    covariance: np.ndarray\n",
    "    datapoints: np.ndarray\n",
    "    accumulated_distance: float = 0.0\n",
    "    inv_covariance: np.ndarray = None\n",
    "\n",
    "\n",
    "def mahalanobis_distance(x, mean, cov):\n",
    "    try:\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov += np.eye(cov.shape[0]) * 1e-6\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "    diff = x - mean\n",
    "    return diff.T @ inv_cov @ diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_with_gmm(X_train, y_train, classes, M):\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    for current_class in classes:\n",
    "        \n",
    "        # Start with one cluster\n",
    "        cluster_dict[current_class] = []\n",
    "        clusters = cluster_dict[current_class]\n",
    "\n",
    "        class_data = X_train[y_train['Genre'] == current_class] # X_train[mask] - selects the row where the mask is true (works because of pandas)\n",
    "\n",
    "        # Calculate the mean of the current cluster\n",
    "        gmm = GaussianMixture(\n",
    "            n_components    = M,\n",
    "            covariance_type = \"full\",  \n",
    "            random_state    = 0\n",
    "        )\n",
    "\n",
    "        gmm.fit(class_data)\n",
    "\n",
    "        for my, cov in zip(gmm.means_, gmm.covariances_):\n",
    "             clusters.append(\n",
    "                Cluster(\n",
    "                    mean               = my,\n",
    "                    covariance         = cov,\n",
    "                    datapoints         = None,\n",
    "                    accumulated_distance=0.0\n",
    "                )\n",
    "            )\n",
    "        \n",
    "\n",
    "    return cluster_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classes = y_train['Genre'].unique()\n",
    "#print(f\"Classes: {classes}\")\n",
    "M = 60\n",
    "cluster_dict = create_classifier_with_gmm(X_train, y_train, classes, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample(x,cluster_dict):\n",
    "    best_distance = float('inf')\n",
    "    predicted_class = ''\n",
    "\n",
    "    for class_name, clusters in cluster_dict.items(): # For key, values in dict\n",
    "        for cluster in clusters:\n",
    "            d = mahalanobis_distance(x,cluster.mean, cluster.covariance)\n",
    "            if d < best_distance:\n",
    "                best_distance = d\n",
    "                predicted_class = class_name\n",
    "    return predicted_class\n",
    "    \n",
    "\n",
    "predicted_label = classify_sample(X_test[0],cluster_dict)\n",
    "print(f\"Predicted label: {predicted_label}. True label: {y_test.iloc[0]['Genre']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, cluster_dict):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        label = classify_sample(x, cluster_dict)\n",
    "        predictions.append(label)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_true = y_test['Genre']\n",
    "y_pred = predict(X_test, cluster_dict)\n",
    "\n",
    "accuracy = accuracy_score(y_test_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
