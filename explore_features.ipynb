{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEA\n",
    "\n",
    "\n",
    "1) Analyze one feature at the time to see if it can be used to discriminate one or more classes from the rest\n",
    "2) Analyze the feature vector as a whole – see if there is any correlation between the vector elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "data = pd.read_csv('data/GenreClassData_30s.txt', sep='\\t')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = data[data['Type'] == 'Train']\n",
    "test = data[data['Type'] == 'Test']\n",
    "\n",
    "# Define the features and targets\n",
    "features = ['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean', 'tempo']\n",
    "features = [\n",
    "    'zero_cross_rate_mean','zero_cross_rate_std','rmse_mean','rmse_var',\n",
    "    'spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var',\n",
    "    'spectral_rolloff_mean','spectral_rolloff_var','spectral_contrast_mean','spectral_contrast_var',\n",
    "    'spectral_flatness_mean','spectral_flatness_var',\n",
    "    'chroma_stft_7_mean',\n",
    "    \n",
    "    'tempo',\n",
    "    'mfcc_1_mean','mfcc_2_mean','mfcc_3_mean','mfcc_4_mean','mfcc_5_mean','mfcc_6_mean',\n",
    "\n",
    "    'mfcc_2_std','mfcc_3_std','mfcc_4_std','mfcc_5_std', 'mfcc_7_std'\n",
    "]\n",
    "\n",
    "\n",
    "targets = ['Genre']\n",
    "\n",
    "\n",
    "# feature data..\n",
    "X_train = train[features]\n",
    "# genre data\n",
    "y_train = train[targets]\n",
    "\n",
    "X_test, y_test = test[features], test[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_to_check = ['spectral_rolloff_mean', 'spectral_centroid_mean', 'tempo']\n",
    "max_values = train[features_to_check].max()\n",
    "min_values = train[features_to_check].min()\n",
    "\n",
    "# Display the results\n",
    "print(\"Max values:\")\n",
    "print(max_values)\n",
    "print(\"\\nMin values:\")\n",
    "print(min_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all') #Clear any existing figures\n",
    "\n",
    "data_dict = {\n",
    "    'hiphop': data[data['Genre'] == 'hiphop'],\n",
    "    'rock': data[data['Genre'] == 'rock'],\n",
    "    'jazz': data[data['Genre'] == 'jazz'],\n",
    "    'classical': data[data['Genre'] == 'classical'],\n",
    "    'reggae': data[data['Genre'] == 'reggae'],\n",
    "    'blues': data[data['Genre'] == 'blues'],\n",
    "    'disco': data[data['Genre'] == 'disco'],\n",
    "    'metal': data[data['Genre'] == 'metal'],\n",
    "    'country': data[data['Genre'] == 'country'],\n",
    "    'pop': data[data['Genre'] == 'pop']\n",
    "}\n",
    "\n",
    "\n",
    "data_dict_prev = {\n",
    "   \n",
    "    'classical': data[data['Genre'] == 'classical'],\n",
    "    'disco': data[data['Genre'] == 'disco'],\n",
    "    'metal': data[data['Genre'] == 'metal'],\n",
    "    'pop': data[data['Genre'] == 'pop']\n",
    "}\n",
    "\n",
    "# for key, value in dict.items():\n",
    "\n",
    "for feature in features:\n",
    "    fig, axes = plt.subplots(len(data_dict),1, figsize=(8,len(data_dict)*3), sharex=True )\n",
    "    for ax, (genre, data)  in zip(axes, data_dict.items()):\n",
    "        ax.hist(data[feature], bins=30, label=feature)\n",
    "        ax.legend()\n",
    "        ax.title.set_text(genre)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a title or section in markdown, use the `#` symbol followed by a space and the title text. The number of `#` symbols determines the heading level.\n",
    "\n",
    "```markdown\n",
    "# Title for the Section\n",
    "\n",
    "## Subsection Title\n",
    "\n",
    "### Sub-subsection Title\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```markdown\n",
    "# Data Analysis\n",
    "\n",
    "## Feature Distribution\n",
    "\n",
    "### Tempo Analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUTUAL INFORMATION BETWEEN FEATURES AND BETWEEN FEATURES AND THE TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and targets\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "all_features = [col for col in data.columns if col not in [\n",
    "    'Track ID','TrackID', 'File', 'GenreID', 'Genre', 'Type',\n",
    "    'spectral_flatness_mean', 'spectral_centroid_mean', 'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'spectral_rolloff_var', 'spectral_rolloff_mean',\n",
    "    'spectral_contrast_mean', 'spectral_contrast_var', 'spectral_centroid_var',\n",
    "    'mfcc_2_mean', 'mfcc_5_mean','mfcc_8_mean','mfcc_9_mean','mfcc_10_mean','mfcc_11_mean','mfcc_12_mean',\n",
    "    'mfcc_2_std','mfcc_3_std','mfcc_4_std','mfcc_5_std','mfcc_7_std','mfcc_8_std', 'mfcc_9_std','mfcc_10_std','mfcc_11_std','mfcc_12_std',\n",
    "    'chroma_stft_1_std','chroma_stft_3_std', 'zero_cross_rate_std'\n",
    "    ]]\n",
    "\n",
    "all_features = [col for col in data.columns if col not in [\n",
    "    'Track ID','TrackID', 'File', 'GenreID', 'Genre', 'Type']]\n",
    "\n",
    "all_features = [\n",
    "    'zero_cross_rate_mean','zero_cross_rate_std','rmse_mean','rmse_var',\n",
    "    'spectral_centroid_mean','spectral_centroid_var','spectral_bandwidth_mean','spectral_bandwidth_var',\n",
    "    'spectral_rolloff_mean','spectral_rolloff_var','spectral_contrast_mean','spectral_contrast_var',\n",
    "    'spectral_flatness_mean','spectral_flatness_var',\n",
    "    'chroma_stft_7_mean',\n",
    "    \n",
    "    'tempo',\n",
    "    'mfcc_1_mean','mfcc_2_mean','mfcc_3_mean','mfcc_4_mean','mfcc_5_mean','mfcc_6_mean',\n",
    "\n",
    "    'mfcc_2_std','mfcc_3_std','mfcc_4_std','mfcc_5_std', 'mfcc_7_std'\n",
    "]\n",
    "targets = ['Genre']\n",
    "\n",
    "\n",
    "# feature data\n",
    "X_train = train[all_features]\n",
    "# genre data\n",
    "y_train = train[targets]\n",
    "\n",
    "X_test, y_test = test[all_features], test[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train, y_train.values.ravel())\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# 1) compute MI (note the .ravel())\n",
    "mi_scores = mutual_info_classif(\n",
    "    X_train,\n",
    "    y_train.values.ravel(),\n",
    "    discrete_features=False,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 2) wrap in a Series and sort *ascending* so the largest end up at top\n",
    "mi = pd.Series(mi_scores, index=X_train.columns)\n",
    "mi = mi.sort_values(ascending=True)\n",
    "\n",
    "# 3) horizontal barplot\n",
    "row_height = 0.3\n",
    "plt.figure(figsize=(10, len(all_features)*row_height))\n",
    "mi.plot(kind='barh')\n",
    "plt.title('Mutual Information Scores by Feature')\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) split at \"tempo\"\n",
    "idx = all_features.index(\"tempo\")\n",
    "feat1 = all_features[:idx+1]\n",
    "feat2 = all_features[idx+1:]\n",
    "\n",
    "def plot_clustered_mi(features, title):\n",
    "    # 2) bin into 10 quantile‐bins\n",
    "    binned = pd.DataFrame({\n",
    "        f: pd.qcut(X_train[f], q=10, duplicates=\"drop\").cat.codes\n",
    "        for f in features\n",
    "    })\n",
    "\n",
    "    # 3) build MI matrix\n",
    "    n = len(features)\n",
    "    M = np.zeros((n, n))\n",
    "    for i, f1 in enumerate(features):\n",
    "        for j, f2 in enumerate(features):\n",
    "            M[i, j] = mutual_info_score(binned[f1], binned[f2])\n",
    "\n",
    "    \n",
    "    g = sns.clustermap(\n",
    "        M,\n",
    "        row_cluster=True,\n",
    "        col_cluster=True,\n",
    "        figsize=(12, 10),\n",
    "        xticklabels=features,\n",
    "        yticklabels=features,\n",
    "        cmap=\"viridis\",\n",
    "        square=True\n",
    "    )\n",
    "    # give it a title\n",
    "    g.fig.suptitle(title, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# now call it for the two halves\n",
    "plot_clustered_mi(feat1, \"Mutual Information Between Features'\")\n",
    "plot_clustered_mi(feat2, \"Clustered MI for MFCC features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) bin data as before\n",
    "binned = pd.DataFrame({\n",
    "    f: pd.qcut(X_train[f], 10, duplicates='drop').cat.codes\n",
    "    for f in all_features\n",
    "})\n",
    "\n",
    "# 2) compute pairwise MI\n",
    "M = np.zeros((len(all_features), len(all_features)))\n",
    "for i, f1 in enumerate(all_features):\n",
    "    for j, f2 in enumerate(all_features):\n",
    "        M[i, j] = mutual_info_score(binned[f1], binned[f2])\n",
    "\n",
    "\n",
    "g = sns.clustermap(\n",
    "    M,\n",
    "    row_cluster=True,\n",
    "    col_cluster=True,\n",
    "    figsize=(16, 12),\n",
    "    xticklabels=all_features,\n",
    "    yticklabels=all_features,\n",
    "    cmap=\"viridis\",\n",
    "   \n",
    "    square=True\n",
    ")\n",
    "plt.suptitle(\"Clustered MI Between Features\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "# 1) Create the mask of \"low‑MI\" cells\n",
    "mask = M < 0.5\n",
    "\n",
    "\n",
    "n = len(all_features)\n",
    "\n",
    "# 0.2 inches per feature in each direction (so 60 features ⇒ 12 inches)\n",
    "size = max(8, n * 0.2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(size, size))\n",
    "\n",
    "# 4) Draw the heatmap\n",
    "sns.heatmap(\n",
    "    M,\n",
    "    mask=mask,\n",
    "    cmap=\"viridis\",\n",
    "    xticklabels=all_features,\n",
    "    yticklabels=all_features,\n",
    "    square=True\n",
    ")\n",
    "\n",
    "plt.title(\"Only MI ≥ 0.5\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1) compute correlations\n",
    "corr = X_train.corr()\n",
    "\n",
    "# 2) display the raw matrix (you’ll see a pandas DataFrame)\n",
    "print(\"Feature–Feature Correlation Matrix:\")\n",
    "display(corr)  \n",
    "\n",
    "# 3) plot a heat-map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pcolor(corr)   # default colormap\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)),    corr.index)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) (optional) list out pairs with |corr| > 0.8\n",
    "threshold = 0.8\n",
    "pairs = corr.abs().unstack().sort_values(ascending=False)\n",
    "high_corr = pairs[(pairs < 1.0) & (pairs > threshold)]\n",
    "print(\"\\nHighly correlated feature pairs (|corr| > 0.8):\")\n",
    "print(high_corr.drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
