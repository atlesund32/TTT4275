{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exploration of k-NN***\n",
    "\n",
    "This file contains the code for the k-NN classifier and some plots and figures used for feature exploration of this classifier. It corresponds to task 1, 3 and parts of 4.\n",
    "\n",
    "\n",
    "In order to run the k-NN classifier with the features corresponding to each task, modify the task variable in the cell below. In order to get the best performing k-NN use \"task = 4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/GenreClassData_30s.txt', sep='\\t')\n",
    "data[\"TrackID\"] = range(len(data))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = data[data['Type'] == 'Train']\n",
    "test = data[data['Type'] == 'Test']\n",
    "\n",
    "all_features = [col for col in data.columns if col not in ['Track ID','TrackID', 'File', 'GenreID', 'Genre', 'Type']]\n",
    "\n",
    "#Choose which task (1, 3 or 4) that you wish to complete by setting the \"task\" to the appropriate value\n",
    "task = 3\n",
    "\n",
    "if task == 1:\n",
    "    features = ['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean','tempo']\n",
    "elif task == 3:\n",
    "    features = ['spectral_rolloff_mean', 'rmse_var', 'spectral_centroid_mean','tempo','mfcc_1_mean']\n",
    "elif task == 4:\n",
    "    features = ['spectral_rolloff_mean','rmse_var', 'spectral_centroid_mean','tempo', 'mfcc_7_mean','mfcc_5_mean','mfcc_6_mean', 'rmse_mean',\n",
    "            'mfcc_7_std','mfcc_11_mean','spectral_bandwidth_var','mfcc_8_mean', \n",
    "            'spectral_contrast_var','mfcc_1_mean','spectral_bandwidth_mean'] #Best k-NN result: 71.71%\n",
    "\n",
    "targets = ['Genre']\n",
    "# feature data\n",
    "X_train = train[features]\n",
    "\n",
    "# genre data\n",
    "y_train = train[targets]\n",
    "X_test, y_test = test[features], test[targets]\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    X_train_np = X_train.to_numpy()\n",
    "    X_test_np = X_test.to_numpy()\n",
    "\n",
    "    means = np.mean(X_train_np, axis=0)\n",
    "    stds = np.std(X_train_np, axis=0)\n",
    "    \n",
    "    X_train_scaled = (X_train_np - means) / stds\n",
    "    X_test_scaled = (X_test_np - means) / stds\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***k-NN algorithm***\n",
    "\n",
    "Below is the k-NN algorithm. The function get_kNN returns a list of predicted every classified audiotrack from the training-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucledian_distance(sample_1, sample_2):\n",
    "    distance = 0\n",
    "    for i in range(len(sample_1)):\n",
    "        distance += (sample_1[i] - sample_2[i]) ** 2\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "\n",
    "def get_feature_matrix(X_train_array, y_train_df): #feature matrix is a Nx(len(features)+1) matrix where the first element of each row is the label\n",
    "    genre_column = y_train_df.values.reshape(-1, 1)  # Convert to Nx1 numpy array\n",
    "    feature_matrix_with_genre = np.hstack((genre_column, X_train_array))\n",
    "    return feature_matrix_with_genre\n",
    "\n",
    "\n",
    "\n",
    "# Compute distances and find k nearest neighbors\n",
    "def compute_distances(feature_matrix, X_test_sample):\n",
    "    distances = []\n",
    "    for i in range(len(feature_matrix)):\n",
    "        distance = eucledian_distance(feature_matrix[i][1:], X_test_sample)  # Ignore genre column\n",
    "        distances.append((feature_matrix[i][0], distance))  # Append genre and distance\n",
    "    return distances\n",
    "\n",
    "def get_kNN(k, X_train_array, y_train_df, X_test_array):\n",
    "    feature_matrix = get_feature_matrix(X_train_array, y_train_df)\n",
    "    label_vector = [] #stores every classified prediction\n",
    "   \n",
    "    for i in range(len(X_test_array)):\n",
    "        distances = compute_distances(feature_matrix,X_test_array[i]) #returns the distance of each from each test with the other features in feature matrix\n",
    "\n",
    "        sorted_distances = sorted(distances, key=lambda x: x[1])  # Sort by distance\n",
    "        k_closest_labels = sorted_distances[:k]\n",
    "\n",
    "        labels = [label for label, _ in k_closest_labels]  # Extract the k closest labels\n",
    "        count = Counter(labels) \n",
    "        most_common_label = count.most_common(1)[0][0] #finds the most common label\n",
    "        label_vector.append(most_common_label)\n",
    "    return label_vector\n",
    "\n",
    "predicted_labels = get_kNN(5, X_train_scaled, y_train, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Accuracy functions***\n",
    "\n",
    "To calculate the accuracy for the classifier, the following functions are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\t\t\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_each_genre(actual, predicted): #returns a dictionary with the accuracy of each genre\n",
    "\tgenre_dict = {}\n",
    "\tcorrect = 0\n",
    "\t\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tif actual[i] not in genre_dict:\n",
    "\t\t\t\tgenre_dict[actual[i]] = 0\n",
    "\n",
    "\t\t\tgenre_dict[actual[i]] += 1/20\n",
    "\t\t\t\n",
    "\treturn genre_dict\n",
    "\n",
    "print(accuracy_metric(y_test,predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm for finding the most best feature**\n",
    "\n",
    "Performs k-NN on every candidate feature in order to find the feature that provides the best accuracy with the current feature set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_feature_selection(candidate_features, current_features, train, test, y_train, y_test, k=5): \n",
    "    best_accuracy = 0\n",
    "    best_feature = None\n",
    "    # Iterate over each candidate that is not already selected\n",
    "    for candidate in candidate_features:\n",
    "        new_features = current_features + [candidate]\n",
    "        print(f\"Testing features: {new_features}\")\n",
    "        \n",
    "        # Extract these features for training and testing\n",
    "        X_train_candidate = train[new_features]\n",
    "        X_test_candidate = test[new_features]\n",
    "        \n",
    "        # Scale these feature sets\n",
    "        X_train_scaled_candidate, X_test_scaled_candidate = scale_data(X_train_candidate,X_test_candidate)\n",
    "        \n",
    "        # Run k-NN with the current candidate feature set\n",
    "        predicted = get_kNN(k, X_train_scaled_candidate, y_train, X_test_scaled_candidate)\n",
    "        acc = accuracy_metric(y_test, predicted)\n",
    "        print(f\"Candidate feature '{candidate}' produced accuracy: {acc:.2f}%\")\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_feature = candidate\n",
    "        new_features = np.delete(new_features,len(new_features)-1)\n",
    "    \n",
    "\n",
    "    print(\"\\nBest candidate feature:\", best_feature, \"with accuracy:\", best_accuracy)\n",
    "    return best_feature, best_accuracy\n",
    "\n",
    "\n",
    "candidate_feat = [col for col in all_features if col not in features]\n",
    "\n",
    "\n",
    "# print(knn_feature_selection(candidate_feat, features,train,test,y_train,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Statistical functions, heatmap and scatterplot***\n",
    "\n",
    "Functions for creating a correlation matrix and plotting of heat-map and scatterplot of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_mean(data):\n",
    "    my = 0\n",
    "    for i in range(len(data)):\n",
    "        my += data[i]\n",
    "    return my/len(data)\n",
    "\n",
    "def cov(x_data, y_data):\n",
    "    cov = 0\n",
    "    x_mean = sample_mean(x_data)\n",
    "    y_mean = sample_mean(y_data)\n",
    "    for i in range(len(x_data)):\n",
    "        cov += (x_data[i]-x_mean)*(y_data[i]-y_mean)\n",
    "    return cov\n",
    "\n",
    "\n",
    "\n",
    "def pearson_correlation(x_data, y_data):\n",
    "    sigX = 0\n",
    "    sigY = 0\n",
    "    x_data_mean = sample_mean(x_data)\n",
    "    y_data_mean = sample_mean(y_data)\n",
    "    \n",
    "    for i in range(len(x_data)):\n",
    "        sigX += (x_data[i] - x_data_mean)**2\n",
    "        sigY += (y_data[i] - y_data_mean)**2\n",
    "\n",
    "    return cov(x_data, y_data)/math.sqrt(sigX*sigY)\n",
    "\n",
    "\n",
    "def get_feature_correlation_matrix(features, train_data):\n",
    "    corr_matrix = []\n",
    "    for i in range(len(features)):\n",
    "        row = []\n",
    "        f_i = train_data[features[i]]\n",
    "        for j in range(len(features)):\n",
    "            f_j = train_data[features[j]]\n",
    "            row.append(pearson_correlation(f_i,f_j))\n",
    "        corr_matrix.append(row)\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "genre_id = train[\"GenreID\"]\n",
    "corr_matrix = get_feature_correlation_matrix(features, train)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Adjust the size of the plot for better readability\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5)\n",
    "\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(X_train_scaled[:,0], X_train_scaled[:,1], X_train_scaled[:,2], c=train['GenreID'], cmap='tab10', s=40)\n",
    "\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "ax.set_title('3D scatterplot of features colored by GenreID')\n",
    "\n",
    "fig.colorbar(scatter, ax=ax, label='GenreID')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X_train_scaled[:, 0],\n",
    "    y=X_train_scaled[:, 1],\n",
    "    z=X_train_scaled[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=train['GenreID'], \n",
    "        colorscale='Viridis',  \n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title = 'GenreID')  \n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=features[0],\n",
    "        yaxis_title=features[1],\n",
    "        zaxis_title=features[2]\n",
    "    ),\n",
    "    title='3D Scatterplot (Standardized Features) colored by GenreID'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PCA-plots***\n",
    "\n",
    "Generates two PCA-plots splitting the genres into two subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genre_mapping = {\n",
    "    0: 'Pop',\n",
    "    1: 'Metal',\n",
    "    2: 'Disco',\n",
    "    3: 'Blues',\n",
    "    4: 'Reggae',\n",
    "    5: 'Classical',\n",
    "    6: 'Rock',\n",
    "    7: 'Hip-hop',\n",
    "    8: 'Country',\n",
    "    9: 'Jazz'\n",
    "}\n",
    "\n",
    "genre_colors = {\n",
    "    'Pop': 'blue',\n",
    "    'Metal': 'red',\n",
    "    'Disco': 'orange',\n",
    "    'Blues': 'purple',\n",
    "    'Reggae': 'green',\n",
    "    'Classical': 'cyan',\n",
    "    'Rock': 'magenta',\n",
    "    'Hip-hop': 'yellow',\n",
    "    'Country': 'brown',\n",
    "    'Jazz': 'pink'\n",
    "}\n",
    "\n",
    "def pca_and_plot_with_fixed_colors(X_scaled, y, title, ax):\n",
    "    # PCA\n",
    "    cov_matrix = np.cov(X_scaled, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvectors = eigenvectors[:, sorted_idx]\n",
    "    principal_components = eigenvectors[:, :2]\n",
    "    X_reduced = np.dot(X_scaled, principal_components)\n",
    "\n",
    "    genre_names = y.map(genre_mapping)\n",
    "\n",
    "    # Plot\n",
    "    unique_genres = genre_names.unique()\n",
    "\n",
    "    for genre in unique_genres:\n",
    "        mask = (genre_names == genre)\n",
    "        ax.scatter(X_reduced[mask, 0], X_reduced[mask, 1],\n",
    "                   label=genre, alpha=0.7, color=genre_colors.get(genre, 'grey'))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "y_train_flat = train['GenreID']  # Retrieves GenreID as Series\n",
    "\n",
    "# Split on GenreID 0–4 and 5–9\n",
    "mask_0_4_rmse = (y_train_flat <= 4)\n",
    "mask_5_9_rmse = (y_train_flat >= 5)\n",
    "\n",
    "X_0_4_rmse = X_train_scaled[mask_0_4_rmse]\n",
    "y_0_4_rmse = y_train_flat[mask_0_4_rmse]\n",
    "\n",
    "X_5_9_rmse = X_train_scaled[mask_5_9_rmse]\n",
    "y_5_9_rmse = y_train_flat[mask_5_9_rmse]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "pca_and_plot_with_fixed_colors(X_0_4_rmse, y_0_4_rmse, 'PCA on Genres \"pop\"-\"raggae\" (with best features)', axs[0])\n",
    "pca_and_plot_with_fixed_colors(X_5_9_rmse, y_5_9_rmse, 'PCA on Genres \"classical\"-\"jazz\" (with best features)', axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
