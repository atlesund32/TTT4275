{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Classification based on Bayesian Decision Rule \n",
    "â€“ which guarentees the Maximum A Posteriori decision\n",
    "\n",
    "\\begin{align}\n",
    "\\hat w(x)\n",
    "&= \\arg\\max_{i}\\;P(w_i \\mid x)\n",
    "= \\arg\\max_{i}\\;\\bigl[p(x \\mid w_i)\\,P(w_i)\\bigr]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In order to do this we need to find \n",
    "\n",
    "\\begin{align}\n",
    "p(x \\mid w_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"data/GenreClassData_30s.txt\", sep=\"\\t\")\n",
    "\n",
    "all_features = [col for col in data.columns if col not in ['Track ID', 'File', 'Genre', 'GenreID', 'Type']]\n",
    "print(all_features)\n",
    "\n",
    "data_train = data[data['Type'] == 'Train']\n",
    "data_test = data[data['Type'] == 'Test']\n",
    "\n",
    "features = all_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = data_train[features], data_train['Genre']\n",
    "X_test, y_test = data_test[features], data_test['Genre']\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(20).fit(X_train_s)\n",
    "X_train_p = pca.transform(X_train_s)\n",
    "X_test_p  = pca.transform(X_test_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def calculate_mean(X):\n",
    "    # Handles pd df and np nd array\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    accumalated_sum = np.zeros(n_features)\n",
    "    for k in range(n_samples):\n",
    "        accumalated_sum += X[k]\n",
    "    \n",
    "    mean = accumalated_sum/n_samples\n",
    "    return mean\n",
    "\n",
    "def calculate_covariance(X, mean):\n",
    "    # Handles pd df and np nd array\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    covariance_matrix = np.zeros((n_features, n_features))\n",
    "    for k in range(n_samples):\n",
    "        diff = X[k] - mean\n",
    "        covariance_matrix += np.outer(diff, diff)\n",
    "\n",
    "    covariance_matrix /= n_samples\n",
    "    return covariance_matrix\n",
    "\n",
    "\n",
    "def mahalanobis_distance(x, mean, inv_cov):\n",
    "    diff = x - mean\n",
    "    return 0.5 * diff.T @ inv_cov @ diff\n",
    "\n",
    "\n",
    "def gaussian_density_model(x, mean, cov, inv_cov):\n",
    "    d = x.shape[0]\n",
    "    det_cov = np.linalg.det(cov)\n",
    "    norm_constant = 1/((2*np.pi)**(d/2) * np.sqrt(det_cov))\n",
    "    exponent = - 0.5 * ((x-mean).T @ inv_cov @ (x-mean))\n",
    "    value = norm_constant * np.exp(exponent)\n",
    "    return value\n",
    "\n",
    "\n",
    "# Creating a dataclass for storing the density models and prior probablities for the classes\n",
    "@dataclass(eq=False)\n",
    "class ClassInformation:\n",
    "    mean: np.ndarray\n",
    "    covariance: np.ndarray\n",
    "    inv_covariance: np.ndarray\n",
    "    a_priori: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def get_class_information(X, y, classes, n_components):\n",
    "    class_information = {}\n",
    "    n_samples, _ = X.shape\n",
    "\n",
    "    for cls in classes:\n",
    "        mask       = (y == cls)\n",
    "        class_data = X[mask]\n",
    "\n",
    "        gmm = GaussianMixture(\n",
    "            n_components    = n_components,\n",
    "            covariance_type = \"full\",\n",
    "            reg_covar       = 1e-3,\n",
    "            random_state    = 0,\n",
    "        )\n",
    "        gmm.fit(class_data)\n",
    "\n",
    "        class_information[cls] = {\n",
    "            \"gmm\"      : gmm,\n",
    "            \"a_priori\" : class_data.shape[0] / n_samples\n",
    "        }\n",
    "\n",
    "    return class_information\n",
    "\n",
    "\n",
    "def classify_map(x, class_info):\n",
    "    best_score = -np.inf\n",
    "    best_class = None\n",
    "\n",
    "    for cls, info in class_info.items():\n",
    "        gmm       = info[\"gmm\"]\n",
    "        log_prior = np.log(info[\"a_priori\"])\n",
    "        # gmm.score_samples returns an array of log p(x) for each row\n",
    "        log_lik   = gmm.score_samples(x.reshape(1, -1))[0]\n",
    "        score     = log_lik + log_prior\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_class = cls\n",
    "\n",
    "    return best_class\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "classes           = np.unique(y_train)\n",
    "class_information = get_class_information(X_train_p, y_train, classes, n_components=9)\n",
    "y_pred            = [classify_map(x, class_information) for x in X_test_p]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:          \", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_map(x, class_info):\n",
    "    best_score = -np.inf\n",
    "    best_class = None\n",
    "\n",
    "    for cls, info in class_info.items():\n",
    "        mean, covariance, covariance_inv, prob_class = info.mean, info.covariance, info.inv_covariance, info.a_priori\n",
    "        \n",
    "\n",
    "        d = x.shape[0]\n",
    "        log_norm = -0.5 * ( d*np.log(2*np.pi)\n",
    "                           + np.log(np.linalg.det(covariance))\n",
    "                           + (x-mean).T @ covariance_inv @ (x-mean) )\n",
    "        log_prior = np.log(prob_class)\n",
    "        score = log_norm + log_prior\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_class = cls\n",
    "\n",
    "    return best_class\n",
    "\n",
    "# predict on the whole test set\n",
    "y_pred = [classify_map(x, class_information) for x in X_test.values]\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
